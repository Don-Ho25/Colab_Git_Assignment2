{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Don-Ho25/Colab_Git_Assignment2/blob/main/Lesson11/Assignment11_AI_ImageClassification_Using_RandomFores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uJZf9BpueAPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment11\n",
        "\n",
        "DONG\n",
        "\n",
        "[GITHUBLINK](https://github.com/Don-Ho25/Colab_Git_Assignment2/blob/main/Lesson11/Assignment11_AI_ImageClassification_Using_RandomFores.ipynb)"
      ],
      "metadata": {
        "id": "PGQ_1iXGZ3LP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We have chosen the MNIST dataset. It is a subset of a larger set available from NIST (http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples.\n"
      ],
      "metadata": {
        "id": "VXX7dFEYZ9RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Selection and Preprocessing:\n",
        "#     Choose a publicly available image dataset suitable for classification. Examples include datasets from Kaggle, UCI Machine Learning Repository, or Google Dataset Search.\n",
        "#     Perform necessary preprocessing steps including:\n",
        "#     Loading the image files.\n",
        "#     Resizing images to a uniform size.\n",
        "#     Normalizing pixel values.\n",
        "#     Splitting the dataset into training and testing sets."
      ],
      "metadata": {
        "id": "fC35LckPaGnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6a05dsr8aPci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. DATA LOADING AND PREPROCESSING\n",
        "print(\"\\n1. LOADING AND PREPROCESSING DATA\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f'Number of training images: {x_train.shape[0]}')\n",
        "print(f'Number of testing images: {x_test.shape[0]}')\n",
        "print(f'Image shape: {x_train.shape[1:]}')\n",
        "print(f'Number of classes: {len(np.unique(y_train))}')\n",
        "\n",
        "# Preprocessing steps\n",
        "def preprocess_data(x_train, x_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Preprocess the MNIST data:\n",
        "    1. Reshape images to 1D arrays\n",
        "    2. Normalize pixel values\n",
        "    3. Handle data types\n",
        "    \"\"\"\n",
        "    # Reshape images from 28x28 to 784 (flattening)\n",
        "    x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "    x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "    # Normalize pixel values to range [0, 1]\n",
        "    x_train_norm = x_train_flat.astype('float32') / 255.0\n",
        "    x_test_norm = x_test_flat.astype('float32') / 255.0\n",
        "\n",
        "    print(f\"Original image shape: {x_train.shape[1:]}\")\n",
        "    print(f\"Flattened shape: {x_train_flat.shape[1]}\")\n",
        "    print(f\"Pixel value range after normalization: [{x_train_norm.min():.1f}, {x_train_norm.max():.1f}]\")\n",
        "\n",
        "    return x_train_norm, x_test_norm, y_train, y_test\n",
        "\n",
        "# Apply preprocessing\n",
        "x_train_processed, x_test_processed, y_train_processed, y_test_processed = preprocess_data(\n",
        "    x_train, x_test, y_train, y_test\n",
        ")\n",
        "\n",
        "# For faster computation, let's use a subset of the data\n",
        "# You can increase these numbers for better accuracy but longer training time\n",
        "TRAIN_SIZE = 10000\n",
        "TEST_SIZE = 2000\n",
        "\n",
        "x_train_subset = x_train_processed[:TRAIN_SIZE]\n",
        "y_train_subset = y_train_processed[:TRAIN_SIZE]\n",
        "x_test_subset = x_test_processed[:TEST_SIZE]\n",
        "y_test_subset = y_test_processed[:TEST_SIZE]\n",
        "\n",
        "print(f\"\\nUsing subset for faster computation:\")\n",
        "print(f\"Training samples: {len(x_train_subset)}\")\n",
        "print(f\"Testing samples: {len(x_test_subset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbfFzFi5ahCn",
        "outputId": "d1892d48-1f70-4d1d-f3ea-41ac27b0dc25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. LOADING AND PREPROCESSING DATA\n",
            "----------------------------------------\n",
            "Number of training images: 60000\n",
            "Number of testing images: 10000\n",
            "Image shape: (28, 28)\n",
            "Number of classes: 10\n",
            "Original image shape: (28, 28)\n",
            "Flattened shape: 784\n",
            "Pixel value range after normalization: [0.0, 1.0]\n",
            "\n",
            "Using subset for faster computation:\n",
            "Training samples: 10000\n",
            "Testing samples: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "zj_UQJzwaXwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. RANDOM FOREST CLASSIFIER\n",
        "print(\"\\n\\n2. RANDOM FOREST CLASSIFIER\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgCLBad3at02",
        "outputId": "62b5ec60-adb4-447b-85de-3ac16e2ecda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "2. RANDOM FOREST CLASSIFIER\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid for GridSearchCV\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "print(\"Parameter grid for Random Forest:\")\n",
        "for param, values in rf_param_grid.items():\n",
        "    print(f\"  {param}: {values}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIWzlpWKa0Cc",
        "outputId": "f10822c5-1411-4e49-a1b6-41d3910f51aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter grid for Random Forest:\n",
            "  n_estimators: [50, 100, 200]\n",
            "  max_depth: [10, 20, None]\n",
            "  min_samples_split: [2, 5, 10]\n",
            "  min_samples_leaf: [1, 2, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "# Perform Grid Search\n",
        "print(\"\\nPerforming Grid Search for Random Forest...\")\n",
        "print(\"This may take a few minutes...\")\n",
        "\n",
        "rf_grid_search = GridSearchCV(\n",
        "    estimator=rf_classifier,\n",
        "    param_grid=rf_param_grid,\n",
        "    cv=3,  # 3-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "rf_grid_search.fit(x_train_subset, y_train_subset)\n",
        "\n",
        "# Get best parameters and model\n",
        "rf_best_params = rf_grid_search.best_params_\n",
        "rf_best_model = rf_grid_search.best_estimator_\n",
        "\n",
        "print(f\"\\nBest Random Forest Parameters:\")\n",
        "for param, value in rf_best_params.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"Best Cross-Validation Score: {rf_grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FByDAFsna79s",
        "outputId": "19eb14b4-eefc-484c-b85e-7201436a71c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing Grid Search for Random Forest...\n",
            "This may take a few minutes...\n",
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
            "\n",
            "Best Random Forest Parameters:\n",
            "  max_depth: 20\n",
            "  min_samples_leaf: 1\n",
            "  min_samples_split: 2\n",
            "  n_estimators: 200\n",
            "Best Cross-Validation Score: 0.9450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. RANDOM FOREST MODEL EVALUATION\n",
        "print(\"\\n\\n3. RANDOM FOREST MODEL EVALUATION\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "1GBhTOelbHSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c74f79f-4f0b-4b86-ebc4-8e295fd80d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "3. RANDOM FOREST MODEL EVALUATION\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "rf_predictions = rf_best_model.predict(x_test_subset)\n",
        "\n",
        "# Calculate metrics\n",
        "rf_accuracy = accuracy_score(y_test_subset, rf_predictions)\n",
        "rf_precision = precision_score(y_test_subset, rf_predictions, average='weighted')\n",
        "rf_recall = recall_score(y_test_subset, rf_predictions, average='weighted')\n",
        "rf_f1 = f1_score(y_test_subset, rf_predictions, average='weighted')\n",
        "\n",
        "print(\"Random Forest Performance Metrics:\")\n",
        "print(f\"  Accuracy:  {rf_accuracy:.4f}\")\n",
        "print(f\"  Precision: {rf_precision:.4f}\")\n",
        "print(f\"  Recall:    {rf_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {rf_f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "rf_cm = confusion_matrix(y_test_subset, rf_predictions)\n",
        "print(f\"\\nConfusion Matrix Shape: {rf_cm.shape}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_subset, rf_predictions))"
      ],
      "metadata": {
        "id": "khJZmFdPbNnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. VISUALIZATIONS\n",
        "print(\"\\n\\n4. CREATING VISUALIZATIONS\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "Q0JISOs-bRA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aad7fc2-ee58-49c0-cfd3-e3c6bdb24aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "4. CREATING VISUALIZATIONS\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subplots for visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Random Forest Model Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: Confusion Matrix\n",
        "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=range(10), yticklabels=range(10), ax=axes[0,0])\n",
        "axes[0,0].set_title('Confusion Matrix - Random Forest')\n",
        "axes[0,0].set_xlabel('Predicted Label')\n",
        "axes[0,0].set_ylabel('True Label')\n",
        "\n",
        "# Plot 2: Feature Importance (top 100 features)\n",
        "rf_feature_importance = rf_best_model.feature_importances_\n",
        "top_features_idx = np.argsort(rf_feature_importance)[-100:]\n",
        "top_features_importance = rf_feature_importance[top_features_idx]\n",
        "\n",
        "axes[0,1].barh(range(len(top_features_importance)), top_features_importance)\n",
        "axes[0,1].set_title('Top 100 Feature Importances - Random Forest')\n",
        "axes[0,1].set_xlabel('Importance')\n",
        "axes[0,1].set_ylabel('Feature Index')\n",
        "\n",
        "# Plot 3: Feature Importance Heatmap (reshaped to 28x28)\n",
        "importance_image = rf_feature_importance.reshape(28, 28)\n",
        "im = axes[1,0].imshow(importance_image, cmap='hot', interpolation='nearest')\n",
        "axes[1,0].set_title('Feature Importance Heatmap (28x28)')\n",
        "axes[1,0].set_xlabel('Pixel Column')\n",
        "axes[1,0].set_ylabel('Pixel Row')\n",
        "plt.colorbar(im, ax=axes[1,0])\n",
        "\n",
        "# Plot 4: Sample predictions\n",
        "sample_indices = np.random.choice(len(x_test_subset), 6, replace=False)\n",
        "for i, idx in enumerate(sample_indices[:6]):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    if i < 6:\n",
        "        # Show original image\n",
        "        if i == 0:\n",
        "            axes[1,1].text(0.5, 0.9, 'Sample Predictions', ha='center',\n",
        "                          transform=axes[1,1].transAxes, fontsize=12, fontweight='bold')\n",
        "\n",
        "        # Create mini subplot for each sample\n",
        "        image = x_test[idx].reshape(28, 28)\n",
        "        true_label = y_test_subset[idx]\n",
        "        pred_label = rf_predictions[idx]\n",
        "\n",
        "        # Simple text display of predictions\n",
        "        prediction_text = f\"Sample {i+1}: True={true_label}, Pred={pred_label}\"\n",
        "        axes[1,1].text(0.05, 0.8 - i*0.12, prediction_text,\n",
        "                      transform=axes[1,1].transAxes, fontsize=10)\n",
        "\n",
        "axes[1,1].axis('off')\n",
        "axes[1,1].set_title('Sample Predictions')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jb8UlKprbYyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. PREDICTION FUNCTION\n",
        "print(\"\\n\\n5. PREDICTION FUNCTION\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "afbbVsw5bchP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_image(model, image_array):\n",
        "    \"\"\"\n",
        "    Predict the class of a new image using the trained model.\n",
        "\n",
        "    Parameters:\n",
        "    model: Trained classifier model\n",
        "    image_array: numpy array of shape (28, 28) or (784,)\n",
        "\n",
        "    Returns:\n",
        "    predicted_class: int\n",
        "    prediction_probability: array\n",
        "    \"\"\"\n",
        "    # Ensure image is in correct format\n",
        "    if len(image_array.shape) == 2:\n",
        "        # If 2D (28x28), flatten it\n",
        "        image_flat = image_array.reshape(1, -1)\n",
        "    else:\n",
        "        # If already 1D, reshape for prediction\n",
        "        image_flat = image_array.reshape(1, -1)\n",
        "\n",
        "    # Normalize if not already normalized\n",
        "    if image_flat.max() > 1:\n",
        "        image_flat = image_flat.astype('float32') / 255.0\n",
        "\n",
        "    # Make prediction\n",
        "    predicted_class = model.predict(image_flat)[0]\n",
        "\n",
        "    # Get prediction probabilities if available\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        prediction_prob = model.predict_proba(image_flat)[0]\n",
        "        return predicted_class, prediction_prob\n",
        "    else:\n",
        "        return predicted_class, None\n",
        "\n",
        "# Test the prediction function with a sample from test set\n",
        "test_image_idx = 0\n",
        "test_image = x_test[test_image_idx]\n",
        "true_label = y_test[test_image_idx]\n",
        "\n",
        "predicted_class, pred_proba = predict_new_image(rf_best_model, test_image)\n",
        "\n",
        "print(f\"Test Image Prediction:\")\n",
        "print(f\"  True Label: {true_label}\")\n",
        "print(f\"  Predicted Label: {predicted_class}\")\n",
        "print(f\"  Prediction Correct: {predicted_class == true_label}\")\n",
        "\n",
        "if pred_proba is not None:\n",
        "    print(f\"  Prediction Probabilities:\")\n",
        "    for i, prob in enumerate(pred_proba):\n",
        "        print(f\"    Class {i}: {prob:.4f}\")"
      ],
      "metadata": {
        "id": "4hscHyKhbiFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. SVM CLASSIFIER (BONUS)\n",
        "print(\"\\n\\n6. SVM CLASSIFIER (BONUS)\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "fjc-oqk4bl14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid for SVM\n",
        "svm_param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['rbf', 'linear'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "print(\"Parameter grid for SVM:\")\n",
        "for param, values in svm_param_grid.items():\n",
        "    print(f\"  {param}: {values}\")\n",
        "\n",
        "# Create SVM classifier\n",
        "svm_classifier = SVC(random_state=42, probability=True)\n",
        "\n",
        "# Perform Grid Search for SVM\n",
        "print(\"\\nPerforming Grid Search for SVM...\")\n",
        "print(\"This may take longer than Random Forest...\")\n",
        "\n",
        "svm_grid_search = GridSearchCV(\n",
        "    estimator=svm_classifier,\n",
        "    param_grid=svm_param_grid,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "svm_grid_search.fit(x_train_subset, y_train_subset)\n",
        "\n",
        "# Get best parameters and model\n",
        "svm_best_params = svm_grid_search.best_params_\n",
        "svm_best_model = svm_grid_search.best_estimator_\n",
        "\n",
        "print(f\"\\nBest SVM Parameters:\")\n",
        "for param, value in svm_best_params.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"Best Cross-Validation Score: {svm_grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "iQludcEudTwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 7. SVM MODEL EVALUATION\n",
        "print(\"\\n\\n7. SVM MODEL EVALUATION\")\n",
        "print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "NENtv1SKdXo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "svm_predictions = svm_best_model.predict(x_test_subset)\n",
        "\n",
        "# Calculate metrics\n",
        "svm_accuracy = accuracy_score(y_test_subset, svm_predictions)\n",
        "svm_precision = precision_score(y_test_subset, svm_predictions, average='weighted')\n",
        "svm_recall = recall_score(y_test_subset, svm_predictions, average='weighted')\n",
        "svm_f1 = f1_score(y_test_subset, svm_predictions, average='weighted')\n",
        "\n",
        "print(\"SVM Performance Metrics:\")\n",
        "print(f\"  Accuracy:  {svm_accuracy:.4f}\")\n",
        "print(f\"  Precision: {svm_precision:.4f}\")\n",
        "print(f\"  Recall:    {svm_recall:.4f}\")\n",
        "print(f\"  F1-Score:  {svm_f1:.4f}\")"
      ],
      "metadata": {
        "id": "lcrV5ka3dbIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_1ZUtvTZuRP"
      },
      "outputs": [],
      "source": [
        "# 8. MODEL COMPARISON\n",
        "print(\"\\n\\n8. MODEL COMPARISON\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "comparison_data = {\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "    'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_f1],\n",
        "    'SVM': [svm_accuracy, svm_precision, svm_recall, svm_f1]\n",
        "}\n",
        "\n",
        "print(\"Performance Comparison:\")\n",
        "print(f\"{'Metric':<12} {'Random Forest':<15} {'SVM':<15} {'Winner':<10}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for i, metric in enumerate(comparison_data['Metric']):\n",
        "    rf_score = comparison_data['Random Forest'][i]\n",
        "    svm_score = comparison_data['SVM'][i]\n",
        "    winner = 'Random Forest' if rf_score > svm_score else 'SVM' if svm_score > rf_score else 'Tie'\n",
        "    print(f\"{metric:<12} {rf_score:<15.4f} {svm_score:<15.4f} {winner:<10}\")\n",
        "\n",
        "# Create comparison visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Performance comparison bar chart\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "rf_scores = [rf_accuracy, rf_precision, rf_recall, rf_f1]\n",
        "svm_scores = [svm_accuracy, svm_precision, svm_recall, svm_f1]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "ax1.bar(x - width/2, rf_scores, width, label='Random Forest', alpha=0.8)\n",
        "ax1.bar(x + width/2, svm_scores, width, label='SVM', alpha=0.8)\n",
        "ax1.set_xlabel('Metrics')\n",
        "ax1.set_ylabel('Score')\n",
        "ax1.set_title('Model Performance Comparison')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(metrics)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Confusion matrices comparison\n",
        "svm_cm = confusion_matrix(y_test_subset, svm_predictions)\n",
        "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=range(10), yticklabels=range(10), ax=ax2)\n",
        "ax2.set_title('Confusion Matrix - SVM')\n",
        "ax2.set_xlabel('Predicted Label')\n",
        "ax2.set_ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. FINAL SUMMARY\n",
        "print(\"\\n\\n9. FINAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(\"PROJECT COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"✓ Dataset: MNIST (Training: {TRAIN_SIZE}, Testing: {TEST_SIZE})\")\n",
        "print(f\"✓ Preprocessing: Normalization and flattening completed\")\n",
        "print(f\"✓ Random Forest: Best accuracy = {rf_accuracy:.4f}\")\n",
        "print(f\"✓ SVM: Best accuracy = {svm_accuracy:.4f}\")\n",
        "print(f\"✓ Winner: {'Random Forest' if rf_accuracy > svm_accuracy else 'SVM' if svm_accuracy > rf_accuracy else 'Tie'}\")\n",
        "print(f\"✓ Visualizations: Confusion matrices, feature importance, and comparisons\")\n",
        "print(f\"✓ Prediction function: Ready for new image classification\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "0xPhCGpsdkUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}